{
  "concepts": [
    {
      "priority": 1,
      "concept": "Anomaly Detection",
      "category": "Observability",
      "definition": "AI-driven identification of abnormal patterns in logs, metrics, or user behavior.",
      "syntax": "// Pseudocode: if anomaly_detected(metrics): trigger_self_heal()",
      "examples": [
        "Monitor CPU usage; if sudden spike, restart process automatically."
      ],
      "explanation": "Anomaly detection enables early intervention and automated healing before users are affected[4][8].",
      "tags": ["observability", "monitoring", "anomaly"],
      "related": ["Automated Repair", "Root Cause Analysis"]
    },
    {
      "priority": 2,
      "concept": "Telemetry Collection",
      "category": "Observability",
      "definition": "Continuous gathering of logs, metrics, traces, and events from all system components.",
      "syntax": "// Use OpenTelemetry or Prometheus exporters",
      "examples": [
        "Collect request latency, error rates, and resource usage for every API endpoint."
      ],
      "explanation": "Comprehensive telemetry is the sensory input for AI self-diagnosis and healing[4][8].",
      "tags": ["telemetry", "observability", "monitoring"],
      "related": ["Anomaly Detection", "Root Cause Analysis"]
    },
    {
      "priority": 3,
      "concept": "Root Cause Analysis",
      "category": "Observability",
      "definition": "AI or rule-based tracing of failures back to their source using logs, traces, and metrics.",
      "syntax": "// Pseudocode: trace_failure(event) => find_root_cause()",
      "examples": [
        "Detect that a database timeout is causing API failures."
      ],
      "explanation": "Root cause analysis enables targeted, effective self-healing actions[4][8].",
      "tags": ["root cause", "diagnosis", "observability"],
      "related": ["Anomaly Detection", "Automated Repair"]
    },
    {
      "priority": 4,
      "concept": "Distributed Monitoring",
      "category": "Observability",
      "definition": "Monitor health and performance across all nodes/services in a distributed system.",
      "syntax": "// Use Datadog, Grafana, or custom dashboards",
      "examples": [
        "Alert if any microservice exceeds 90% CPU for 5 minutes."
      ],
      "explanation": "Distributed monitoring ensures no part of the system is a blind spot for self-diagnosis[4][8].",
      "tags": ["distributed", "monitoring", "observability"],
      "related": ["Telemetry Collection", "Anomaly Detection"]
    },
    {
      "priority": 5,
      "concept": "Automated Alerting",
      "category": "Observability",
      "definition": "Trigger alerts or healing actions automatically when metrics cross defined thresholds.",
      "syntax": "// Pseudocode: if error_rate > 5%: send_alert()",
      "examples": [
        "Restart service if memory usage exceeds safe limit."
      ],
      "explanation": "Automated alerting reduces downtime and enables rapid self-healing responses[4][8].",
      "tags": ["alerting", "automation", "observability"],
      "related": ["Anomaly Detection", "Automated Repair"]
    }
  ]
}
