/**
 * ==========================================================
 * File: /lib/ai-engine/suggestion-engine.ts
 * Project: ZacAI 3.0
 * Role: Proactive Assistance & Intelligent Suggestion Generator
 * Description:
 *   - Analyzes current user prompt, session context, and AI state to generate relevant, proactive suggestions.
 *   - Leverages LLM capabilities for contextual reasoning to provide useful next steps or insights.
 *   - Designed to improve user experience by anticipating needs.
 * Advanced Features:
 *   - Context-aware suggestion generation (user activity, errors, recent topics).
 *   - Customizable suggestion types (questions, actions, resources).
 *   - Integrates with tracing for explainability of suggestions.
 * ==========================================================
 */

import { infer } from "./engine"; // Your main LLM inference function
import { generateTraceStep } from "./explainability"; // For tracing decisions
import { GlobalMemory } from "./memory"; // For accessing user, session, and project memory
import { ProcessedMultimodalOutput } from "./multimodal"; // For multimodal context

/**
 * @interface AISuggestion
 * @description Represents a single suggestion generated by the AI.
 */
export interface AISuggestion {
  id: string; // Unique ID for the suggestion
  type: 'question' | 'action' | 'resource' | 'information'; // Type of suggestion
  text: string; // The suggestion text
  actionPayload?: Record<string, any>; // Optional: Data for a UI action (e.g., pre-fill a code editor)
  relevanceScore?: number; // Optional: A score indicating how relevant this suggestion is
  source?: string; // Optional: Where the suggestion originated (e.g., 'error_analysis', 'user_pattern')
}

/**
 * @function generateSuggestions
 * @description Generates a list of proactive suggestions based on the current AI context.
 * @param currentPrompt The current user input.
 * @param context The comprehensive AI context, including globalMemory and multimodalProcessed.
 * @param currentErrors Optional: Any errors detected during the current processing cycle.
 * @param currentWarnings Optional: Any warnings detected during the current processing cycle.
 * @param previousResponse Optional: The AI's previous response in the conversation.
 * @returns A Promise resolving to an array of AISuggestion objects.
 */
export async function generateSuggestions(
  currentPrompt: string,
  context: {
    userId: string;
    sessionId: string;
    projectId?: string;
    globalMemory: GlobalMemory;
    multimodalProcessed?: ProcessedMultimodalOutput;
    [key: string]: any;
  },
  currentErrors?: string[],
  currentWarnings?: string[],
  previousResponse?: any,
): Promise<AISuggestion[]> {
  generateTraceStep("Suggestion Generation Started", {
    prompt: currentPrompt.slice(0, 100) + "...",
    hasErrors: !!currentErrors?.length,
    hasWarnings: !!currentWarnings?.length,
  });

  try {
    // Construct a comprehensive prompt for the LLM to generate suggestions.
    const suggestionPrompt = `You are a proactive AI assistant. Analyze the user's current situation, the prompt, conversation history, and any system messages (errors/warnings) to generate relevant and helpful suggestions. Provide 1-3 suggestions.

Consider the following:
- User's current prompt: "${currentPrompt}"
- Last AI response: "${JSON.stringify(previousResponse || 'N/A').slice(0, 200)}..."
- Recent conversation history: ${context.globalMemory?.shortTerm?.sessionHistory?.slice(-3).map((interaction, index) =>
      `  ${index + 1}. User: "${interaction.prompt}" -> AI: "${JSON.stringify(interaction.response || 'N/A').slice(0, 100)}..."`
    ).join('\n') || '  No recent conversation history.'}
- User Preferences: ${JSON.stringify(context.globalMemory?.longTermUser?.preferences || {}) || '  No specific preferences.'}
- Project Context: ${context.globalMemory?.project?.codebaseOverview || '  No active project context.'}
- Multimodal Input Analysis: ${multimodalProcessed ? JSON.stringify(multimodalProcessed.summary || 'N/A').slice(0, 200) : 'N/A'}
- Current Errors: ${currentErrors?.length ? currentErrors.join('; ') : 'None'}
- Current Warnings: ${currentWarnings?.length ? currentWarnings.join('; ') : 'None'}
- Detected Domain: ${context.detectedDomain || 'unknown'}

If there are errors or warnings, suggest troubleshooting steps or alternative approaches. If the conversation seems to be ending, suggest related topics or next steps. If the user is asking for code, suggest related tools or best practices.

Respond with a JSON array of suggestions. Each suggestion should have 'id', 'type' (question, action, resource, information), and 'text'. Include an 'actionPayload' for 'action' types if relevant (e.g., {"command": "lintCode", "code": "..."}).

Example JSON structure:
[
  { "id": "sugg-1", "type": "question", "text": "Would you like me to check for syntax errors in your code?" },
  { "id": "sugg-2", "type": "action", "text": "Run code in a sandbox", "actionPayload": {"command": "runCode", "language": "python", "code": "..."} },
  { "id": "sugg-3", "type": "resource", "text": "Learn more about AI best practices here." }
]
`;

    // Call the LLM to generate suggestions
    const { text: llmSuggestionsJson } = await infer(suggestionPrompt, {
      context: { ...context, currentErrors, currentWarnings, previousResponse },
    });

    let suggestions: AISuggestion[] = [];
    try {
      suggestions = JSON.parse(llmSuggestionsJson);
      // Basic validation of parsed suggestions
      if (!Array.isArray(suggestions) || suggestions.some(s => !s.id || !s.type || !s.text)) {
        throw new Error("Invalid JSON structure for suggestions.");
      }
      generateTraceStep("Suggestions Generated by LLM", { count: suggestions.length });
    } catch (parseError: any) {
      generateTraceStep("Suggestion LLM Output Parse Error", { error: parseError.message, llmOutput: llmSuggestionsJson });
      console.warn(`[SuggestionEngine] LLM returned malformed suggestions JSON: ${parseError.message}`);
      // Fallback to default or empty suggestions if parsing fails
      suggestions = [];
    }

    // --- Post-processing/Filtering of Suggestions (Optional) ---
    // You might add logic here to filter out irrelevant suggestions,
    // prioritize certain types, or ensure they don't repeat.
    // For example, if no code was mentioned, filter out code-related suggestions.

    return suggestions;

  } catch (error: any) {
    generateTraceStep("Suggestion Generation Error", { error: error.message });
    console.error(`[SuggestionEngine] Failed to generate suggestions: ${error.message}`);
    return []; // Return empty array on error
  }
}
